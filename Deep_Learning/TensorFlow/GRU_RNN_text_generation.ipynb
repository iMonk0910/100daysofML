{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWLJUpM048Ef"
      },
      "source": [
        "# Text Generation with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e8VlyAD348Er"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeIIcG1l48Et"
      },
      "source": [
        "## Data\n",
        "\n",
        "Website : https://www.gutenberg.org/\n",
        "\n",
        "All of shakespeare's works\n",
        "\n",
        "A very large corpus of text (Large number of text date required for realistic text generation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PlC-Z8HV48Ev"
      },
      "outputs": [],
      "source": [
        "text = open('/content/shakespeare.txt', mode='r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "rxNoVImI48Ev",
        "outputId": "55abfb08-a9bb-439a-f5a9-a03fdb91bcb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ81b6FN48Ex"
      },
      "source": [
        "## Unique characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv9O8CME48Ex",
        "outputId": "35c9f73b-9b67-44fe-9e57-c8ecd8dff7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
          ]
        }
      ],
      "source": [
        "vocab = sorted(set(text))\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu4oPAsH48Ey",
        "outputId": "a8ffb799-a21b-48e0-b406-ef5dbd913685"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4b_3ZRx48Ey"
      },
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw3xJHCE48Ez"
      },
      "source": [
        "### Indexing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7-zjTNUb48Ez"
      },
      "outputs": [],
      "source": [
        "char_to_index = {char:index for index,char in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CGEVZjk48E0",
        "outputId": "6897ca3e-1447-4ab8-f399-03c1380793fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "char_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bNF06E248E0",
        "outputId": "38403546-fd99-4f63-e643-7c89a6cc84d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "char_to_index['1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ww6RgMWd48E1"
      },
      "outputs": [],
      "source": [
        "index_to_char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqSzFWov48E1",
        "outputId": "a88fac07-c4bf-42db-8d72-4491ea008eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "index_to_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UGbgv33o48E2",
        "outputId": "2a32d358-f77a-46a9-cab4-4e894fa01429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'S'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "index_to_char[44]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-binYIF348E2"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z4nmBePJ48E2"
      },
      "outputs": [],
      "source": [
        "encoded_text = np.array([char_to_index[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH6drQDL48E3",
        "outputId": "d8413401-b798-4fd5-f5ad-fb20e8ea1c1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 78, 63, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd1zo_6y48E3",
        "outputId": "a1d31fa1-3cd1-4992-91e3-d50788f82f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2097152,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "encoded_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "l8DqsqBt48E4",
        "outputId": "6272be46-3354-4d73-b4b7-c3dd40023193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sample = text[:500]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbZvZttE48E4",
        "outputId": "94c107dd-1bb9-49b5-9f5f-a4d21bb801fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "encoded_sample = encoded_text[:500]\n",
        "encoded_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtTpbCRf48E5"
      },
      "source": [
        "## Creating Batches\n",
        "\n",
        "model will try to predict the next highest probability character given a historical sequence of characters. \n",
        "\n",
        "\n",
        "Length of historic sequence\n",
        "\n",
        "\n",
        "    Too short a sequence and don't have enough information (e.g. given the letter \"a\" , what is the next character)\n",
        "    too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. \n",
        "+ While there is no correct sequence length choice, consider \n",
        "    + the text itself, \n",
        "    + how long normal phrases are in it, and \n",
        "    + a reasonable idea of what characters/words are relevant to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uohp13Yp48E5"
      },
      "source": [
        "## Understanding the text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWchdZOb48E5",
        "outputId": "2d88bda0-e111-4758-b585-44fade26b33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6FHHqMr48E6",
        "outputId": "c948333d-ec7a-43ee-ab6d-a707c4d2cf57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "lines = 'From fairest creatures we desire increase,'\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBqwUoNu48E6"
      },
      "source": [
        "As Shakespears writing's include rhymes between the lines.\n",
        "Pick up at least 3 lines to pick up those patterns.\n",
        "\n",
        "Example: check out the ending words. They do rhyme, such as `increase, decrease` , `die , eyes, lies`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06HKIqKP48E6",
        "outputId": "c2ec33dc-ac43-41c9-a11a-24143c338a0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "lines = '''\n",
        " From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "'''\n",
        "\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSGFsKcb48E7"
      },
      "source": [
        "## Training Sequences\n",
        "\n",
        "The actual text data will be the text sequence shifted one character forward. For example:\n",
        "\n",
        "**Sequence In: \"Hello my nam\"**\n",
        "\n",
        "**Sequence Out: \"ello my name\"**\n",
        "\n",
        "\n",
        "We can use the `tf.data.Dataset.from_tensor_slices` function to convert a text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9RP5gyFE48E8"
      },
      "outputs": [],
      "source": [
        "sequence_length = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2tiAr7Qq48E9"
      },
      "outputs": [],
      "source": [
        "total_num_sequence = len(text) // (sequence_length+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O19TlUy548E9",
        "outputId": "8e30cd32-ca4f-46e5-cf6d-3db242a64006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17331"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "total_num_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "d0yDuPHW48E-"
      },
      "outputs": [],
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NLwdbZQ48E-",
        "outputId": "3406342b-9abe-4b8e-c1ab-7261be56bb47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "type(char_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQGwwPG448E-",
        "outputId": "2f1dfda4-8fc9-4020-decd-f7b4c84d5575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ],
      "source": [
        "for item in char_dataset.take(500):\n",
        "    print(index_to_char[item.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEcOnKxU48E_"
      },
      "source": [
        "### Creating Sequence Batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-m14suo48E_"
      },
      "source": [
        " `Drop_remainder` :\n",
        "\n",
        "    Drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
        "    whether the last batch should be dropped in the case it has fewer than\n",
        "    `batch_size` elements; the default behavior is not to drop the smaller\n",
        "    batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xlTj7h8_48FA"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGGcTBHO48FB",
        "outputId": "9d983a98-f573-4432-9c16-689f22bc681a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=TensorSpec(shape=(121,), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc7GxtN248FB"
      },
      "source": [
        "####Create target text sequences:\n",
        "\n",
        "Grab the input text sequence\n",
        "\n",
        "Assign the target text sequence as the input text sequence shifted by one step forward\n",
        "\n",
        "Group them together as a tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Nf35m5Hi48FB"
      },
      "outputs": [],
      "source": [
        "def create_sequence_targets(seq):\n",
        "    input_txt = seq[:-1] # Hello my nam\n",
        "    target_txt = seq[1:] # ello my name\n",
        "    return (input_txt, target_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pqlzGaw448FC"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(tf.autograph.experimental.do_not_convert(create_sequence_targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skiBZ66b48FC",
        "outputId": "fbcb7fa5-1c2d-40a1-abfa-27de83a59978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "\n",
        "    print(input_txt.numpy())\n",
        "    print(\"\".join(index_to_char[input_txt.numpy()]))\n",
        "    \n",
        "    print('\\n')\n",
        "    \n",
        "    \n",
        "    print(target_txt.numpy())\n",
        "    print(\"\".join(index_to_char[target_txt.numpy()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmig2ZZt48FD"
      },
      "source": [
        "### Generating Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9y4LGtze48FD"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "buffer_size = 1000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJoTu6mC48FD",
        "outputId": "e56f2d63-cc6b-4f4f-d4a0-0322a085ebb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR16m-mm48FE"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ADJOSPlO48FF"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension \n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfy8UkLG48FF",
        "outputId": "e8233e65-fffe-45ae-ad30-00dc1302ed35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "vocab_size "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CTWgu_4E48FG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "N5MhEnFO48FG"
      },
      "outputs": [],
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_Bm12Rij48FH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ybDlKJaZ48FH"
      },
      "outputs": [],
      "source": [
        "#Setting up Model Function\n",
        "\n",
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
        "    \n",
        "    model.add(GRU(rnn_neurons,\n",
        "                          return_sequences=True,\n",
        "                          stateful=True,\n",
        "                          recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    model.add(Dense(vocab_size))\n",
        "    \n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "oz9-dmpH48FH"
      },
      "outputs": [],
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhMkKmYN48FI",
        "outputId": "07273949-a8f4-47fa-d9f4-fb3a3988661b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5312      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 83)           85241     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,451,729\n",
            "Trainable params: 3,451,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPok-9c848FI"
      },
      "source": [
        "## Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sSk5z0Y48FI",
        "outputId": "adf89fe0-2dd5-4b5b-f8ba-3f093424a8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 83)  <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTklWCLG8ztK",
        "outputId": "c619b993-f673-458a-b088-fe123f908c01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 83])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "example_batch_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqSfqsDl88rh",
        "outputId": "b2ddc220-a2ba-416a-e091-3946ac0d761d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 83), dtype=float32, numpy=\n",
              "array([[ 4.2124642e-03,  7.3780920e-03,  4.3778191e-04, ...,\n",
              "        -2.8053438e-03, -1.5491958e-03, -2.2309874e-03],\n",
              "       [-2.0576089e-04,  3.1742894e-03,  7.0315355e-04, ...,\n",
              "         2.2278122e-04, -3.1104316e-03,  1.0511335e-03],\n",
              "       [-1.8069755e-03,  5.4872746e-04,  1.7769056e-04, ...,\n",
              "         2.0268445e-03, -4.6364199e-03,  2.1188839e-03],\n",
              "       ...,\n",
              "       [ 4.9558384e-03,  5.3273477e-03, -4.6511053e-04, ...,\n",
              "        -2.0526445e-03, -5.7539325e-03, -2.6582757e-03],\n",
              "       [ 1.5547297e-04,  1.6597235e-03, -9.7347991e-05, ...,\n",
              "         6.7029591e-04, -6.0118446e-03,  7.4897712e-04],\n",
              "       [-1.7472229e-03, -5.4388103e-04, -3.3778269e-04, ...,\n",
              "         2.2391872e-03, -6.4067361e-03,  1.9473135e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "example_batch_predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAtqwfGZ9IId"
      },
      "source": [
        "Probabilities for each characters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xxWvIXJ19Cbh"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUfpL1Y29u6f",
        "outputId": "0beaf8fd-4f71-4cc7-8ea0-c82d6ea74aaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[55],\n",
              "       [50],\n",
              "       [79],\n",
              "       [24],\n",
              "       [10],\n",
              "       [31],\n",
              "       [30],\n",
              "       [46],\n",
              "       [50],\n",
              "       [38],\n",
              "       [53],\n",
              "       [71],\n",
              "       [10],\n",
              "       [61],\n",
              "       [33],\n",
              "       [22],\n",
              "       [16],\n",
              "       [37],\n",
              "       [72],\n",
              "       [33],\n",
              "       [61],\n",
              "       [39],\n",
              "       [14],\n",
              "       [51],\n",
              "       [15],\n",
              "       [78],\n",
              "       [27],\n",
              "       [31],\n",
              "       [62],\n",
              "       [72],\n",
              "       [71],\n",
              "       [20],\n",
              "       [61],\n",
              "       [ 9],\n",
              "       [ 9],\n",
              "       [66],\n",
              "       [22],\n",
              "       [57],\n",
              "       [73],\n",
              "       [ 7],\n",
              "       [37],\n",
              "       [19],\n",
              "       [ 4],\n",
              "       [67],\n",
              "       [29],\n",
              "       [13],\n",
              "       [16],\n",
              "       [ 6],\n",
              "       [12],\n",
              "       [23],\n",
              "       [69],\n",
              "       [75],\n",
              "       [37],\n",
              "       [29],\n",
              "       [63],\n",
              "       [61],\n",
              "       [60],\n",
              "       [46],\n",
              "       [25],\n",
              "       [49],\n",
              "       [ 1],\n",
              "       [38],\n",
              "       [24],\n",
              "       [ 7],\n",
              "       [38],\n",
              "       [47],\n",
              "       [14],\n",
              "       [ 4],\n",
              "       [72],\n",
              "       [40],\n",
              "       [58],\n",
              "       [45],\n",
              "       [26],\n",
              "       [16],\n",
              "       [49],\n",
              "       [32],\n",
              "       [37],\n",
              "       [10],\n",
              "       [62],\n",
              "       [32],\n",
              "       [ 3],\n",
              "       [53],\n",
              "       [76],\n",
              "       [64],\n",
              "       [ 1],\n",
              "       [48],\n",
              "       [81],\n",
              "       [ 2],\n",
              "       [28],\n",
              "       [40],\n",
              "       [71],\n",
              "       [ 7],\n",
              "       [38],\n",
              "       [36],\n",
              "       [13],\n",
              "       [38],\n",
              "       [ 3],\n",
              "       [57],\n",
              "       [80],\n",
              "       [45],\n",
              "       [20],\n",
              "       [17],\n",
              "       [30],\n",
              "       [75],\n",
              "       [55],\n",
              "       [14],\n",
              "       [36],\n",
              "       [13],\n",
              "       [49],\n",
              "       [72],\n",
              "       [72],\n",
              "       [68],\n",
              "       [38],\n",
              "       [48],\n",
              "       [17],\n",
              "       [60],\n",
              "       [18],\n",
              "       [30],\n",
              "       [42],\n",
              "       [67]])>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "DulCOrnp9wEr"
      },
      "outputs": [],
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfD-fJj09xmD",
        "outputId": "4ad5e931-cc94-490d-a747-dc652aadf00a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([55, 50, 79, 24, 10, 31, 30, 46, 50, 38, 53, 71, 10, 61, 33, 22, 16,\n",
              "       37, 72, 33, 61, 39, 14, 51, 15, 78, 27, 31, 62, 72, 71, 20, 61,  9,\n",
              "        9, 66, 22, 57, 73,  7, 37, 19,  4, 67, 29, 13, 16,  6, 12, 23, 69,\n",
              "       75, 37, 29, 63, 61, 60, 46, 25, 49,  1, 38, 24,  7, 38, 47, 14,  4,\n",
              "       72, 40, 58, 45, 26, 16, 49, 32, 37, 10, 62, 32,  3, 53, 76, 64,  1,\n",
              "       48, 81,  2, 28, 40, 71,  7, 38, 36, 13, 38,  3, 57, 80, 45, 20, 17,\n",
              "       30, 75, 55, 14, 36, 13, 49, 72, 72, 68, 38, 48, 17, 60, 18, 30, 42,\n",
              "       67])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HINtlaGV9zJ_",
        "outputId": "21042e9a-3e6b-4edc-d565-f684c932b9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "\n",
            "    Shall profit thee, and much enrich thy book.\n",
            "\n",
            "\n",
            "                     78\n",
            "  So oft have I invoked thee for my muse,\n",
            "  \n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "`Yx>.FEUYM]p.fH;5LqHfN3Z4wBFgqp9f--k;br)L8&lD25(1<ntLDhfeU?X M>)MV3&qOcTA5XGL.gG\"]ui Wz!COp)MK2M\"byT96Et`3K2XqqmMW6e7EQl\n"
          ]
        }
      ],
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(index_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(index_to_char[sampled_indices ]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLpsOC997dB"
      },
      "source": [
        "These are just random predictions of characters as model hasn't trained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vLCXU1D790s7"
      },
      "outputs": [],
      "source": [
        "epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWvr8B6O-A4o",
        "outputId": "f027fae7-c66d-4ba2-98fd-5633c282899b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "135/135 [==============================] - 19s 127ms/step - loss: 3.1244\n",
            "Epoch 2/30\n",
            "135/135 [==============================] - 18s 129ms/step - loss: 2.2482\n",
            "Epoch 3/30\n",
            "135/135 [==============================] - 19s 138ms/step - loss: 1.9914\n",
            "Epoch 4/30\n",
            "135/135 [==============================] - 19s 137ms/step - loss: 1.8017\n",
            "Epoch 5/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.6471\n",
            "Epoch 6/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.5276\n",
            "Epoch 7/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.4442\n",
            "Epoch 8/30\n",
            "135/135 [==============================] - 19s 139ms/step - loss: 1.3827\n",
            "Epoch 9/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 1.3356\n",
            "Epoch 10/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 1.2986\n",
            "Epoch 11/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.2679\n",
            "Epoch 12/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.2405\n",
            "Epoch 13/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 1.2169\n",
            "Epoch 14/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.1941\n",
            "Epoch 15/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.1727\n",
            "Epoch 16/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.1527\n",
            "Epoch 17/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 1.1338\n",
            "Epoch 18/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.1133\n",
            "Epoch 19/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.0937\n",
            "Epoch 20/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.0738\n",
            "Epoch 21/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 1.0530\n",
            "Epoch 22/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.0326\n",
            "Epoch 23/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 1.0120\n",
            "Epoch 24/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.9910\n",
            "Epoch 25/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 0.9700\n",
            "Epoch 26/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 0.9504\n",
            "Epoch 27/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 0.9308\n",
            "Epoch 28/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 0.9117\n",
            "Epoch 29/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 0.8949\n",
            "Epoch 30/30\n",
            "135/135 [==============================] - 18s 130ms/step - loss: 0.8780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f68fa530e50>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "model.fit(dataset, epochs = epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7TdvAi1-0Xs"
      },
      "source": [
        "## Generating text\n",
        "\n",
        "The model only expects 128 sequences at a time. \n",
        "\n",
        "Creating a model that only expects a batch_size=1.\n",
        "\n",
        "Then call .build() on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "aw35yLKm-NCE"
      },
      "outputs": [],
      "source": [
        "model.save('/content/shakespeare_gen.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Ja-NmujU-5WK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NefwX-9__Tdu"
      },
      "outputs": [],
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('/content/shakespeare_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yBg3iE_dlm",
        "outputId": "8c60e36d-788c-4703-db57-82c430d4bee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 64)             5312      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 83)             85241     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,451,729\n",
            "Trainable params: 3,451,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4kAnfDGs_doF"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_index[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        " \n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(index_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJXQZxA_dqm",
        "outputId": "6f232e52-f7aa-468c-d5a9-1b457bbc7064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love it you?\n",
            "  EDWARD. A wife to bring your looks, and life; but when a lowly rack,\n",
            "    My wife and lobl\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model,\"love\",gen_size=100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIEEkDVPbykC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-datascience",
      "language": "python",
      "name": "venv-datascience"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
